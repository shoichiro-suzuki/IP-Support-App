# レビューUI LLMサポート計画
- 目的: 審査結果画面でのLLM問い合わせと、LLM対話でのナレッジ生成支援を追加し、運用効率を上げる。
- スコープ: Streamlit UI改修、LLM/ナレッジ連携API追加、ログ/権限/データ保存方針。
- 非スコープ: 新しいDB基盤移行、モデル提供元の変更。

## 要求整理
- 審査結果画面で即時質問: 審査結果表示と同じUIで追質問できるチャットを配置し、審査結果や該当ナレッジをコンテキストに渡す。
- ナレッジ生成支援: 契約案/実績/既存ナレッジを前提に、既存ナレッジ形式で叩き台を生成・編集・保存する対話UIを提供。
- 効率化: コピペ不要、再利用可能なプロンプト/テンプレート、入力エラー防止。

## 方針（初期案）
- LLMクライアント: 既存 `azure_/openai_service` / `api.async_llm_service` を活用し、審査結果チャットは低遅延モデルを選択可能にする。
- 審査結果チャット: `pages/10_examination.py` にチャットパネルを追加。コンテキストは審査結果/ナレッジ/契約基本情報をサマリ化して添付。履歴はセッション内保持。
- ナレッジ生成: 新規ページ `pages/22_knowledge_llm.py`（案）で対話→下書きナレッジを編集→`KnowledgeAPI.save_knowledge` へ保存。下書き保存は `approval_status=draft` で登録。
- ログ/監査: 重要操作（保存/削除/生成リクエスト）を専用コンテナ or ログファイルに記録する案を検討。機密情報はサニタイズ。
- 権限制御: 生成/保存は管理者のみ。閲覧チャットは一般でも可とするか要検討。

## 技術タスク（ドラフト）
- UI: 審査結果チャットパネル追加（チャット履歴、入力、送信、モデル選択、コンテキスト表示切替）。
- UI: ナレッジ生成ページ追加（コンテキストアップロード/選択、下書きプレビュー、保存ボタン）。
- API/サービス: チャット用LLM呼び出しユーティリティ追加（コンテキスト圧縮、トークン上限管理）。
- API/サービス: ナレッジ生成プロンプトとフォーマットチェック（必須項目・長さ制限）。
- データ/ログ: 生成結果の保存ポリシー、監査ログ設計。
- セキュリティ: 管理者認証フック、入力フィルタ、情報漏えい防止ルール。
- UX: エラーハンドリング、ローディング/再試行、Undo/差分提示の検討。

## リスク/検討事項
- トークン超過: 審査結果や条文が長い場合、要約層を挟む必要。
- 機密情報漏えい: 外部LLM送信前の赤入れ/マスキング方針。
- 書式整合: 既存ナレッジのフィールド漏れや形式揺れ。
- レイテンシ: モデル選択と同時実行数制御（セマフォ）で調整。

## 成果物
- 実装: 審査結果チャット機能、ナレッジ生成支援UI + 保存までのフロー。
- ドキュメント: 仕様/プロンプト/運用手順を docs/review-ui-llm-support/ に追記。
